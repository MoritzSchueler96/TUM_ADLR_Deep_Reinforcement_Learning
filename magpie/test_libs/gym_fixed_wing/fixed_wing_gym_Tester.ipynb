{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "conda-env-adlr-py",
   "display_name": "Python [conda env:adlr]",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Reproduce paper results"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "notebookDir: /home/user/Documents/Github/Uni/Master/tum-adlr-ws20-08/magpie/test_libs/gym_fixed_wing\n/home/user/Documents/Github/Uni/Master/tum-adlr-ws20-08/magpie/test_libs/gym_fixed_wing/../../libs/fixed-wing-gym/gym_fixed_wing/examples/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if not 'notebookDir' in globals():\n",
    "    notebookDir = os.getcwd()\n",
    "print('notebookDir: ' + notebookDir)\n",
    "os.chdir(notebookDir)\n",
    "examples_dir = notebookDir + \"/../../libs/fixed-wing-gym/gym_fixed_wing/examples/\"\n",
    "print(examples_dir)"
   ]
  },
  {
   "source": [
    "## Training"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:\nThe TensorFlow contrib module will not be included in TensorFlow 2.0.\nFor more information, please see:\n  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n  * https://github.com/tensorflow/addons\n  * https://github.com/tensorflow/io (for I/O related ops)\nIf you depend on functionality not listed there, please file an issue.\n\n"
     ]
    }
   ],
   "source": [
    "from gym_fixed_wing.examples import train_rl_controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "75 |\n",
      "| serial_timesteps   | 32000         |\n",
      "| time_elapsed       | 1.04e+03      |\n",
      "| total_timesteps    | 128000        |\n",
      "| value_loss         | 0.0021518725  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0006431426  |\n",
      "| clipfrac           | 0.00048828125 |\n",
      "| ep_len_mean        | 1.34e+03      |\n",
      "| ep_reward_mean     | -2.25e+03     |\n",
      "| explained_variance | 0.431         |\n",
      "| fps                | 125           |\n",
      "| n_updates          | 300           |\n",
      "| policy_entropy     | 3.5823138     |\n",
      "| policy_loss        | -0.0031165206 |\n",
      "| serial_timesteps   | 38400         |\n",
      "| time_elapsed       | 1.33e+03      |\n",
      "| total_timesteps    | 153600        |\n",
      "| value_loss         | 0.004943492   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00086747203 |\n",
      "| clipfrac           | 0.005859375   |\n",
      "| ep_len_mean        | 1.41e+03      |\n",
      "| ep_reward_mean     | -2.26e+03     |\n",
      "| explained_variance | 0.966         |\n",
      "| fps                | 129           |\n",
      "| n_updates          | 350           |\n",
      "| policy_entropy     | 3.440208      |\n",
      "| policy_loss        | -0.0058931476 |\n",
      "| serial_timesteps   | 44800         |\n",
      "| time_elapsed       | 1.53e+03      |\n",
      "| total_timesteps    | 179200        |\n",
      "| value_loss         | 0.0029935236  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0005108264  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 1.45e+03      |\n",
      "| ep_reward_mean     | -2.19e+03     |\n",
      "| explained_variance | 0.948         |\n",
      "| fps                | 131           |\n",
      "| n_updates          | 400           |\n",
      "| policy_entropy     | 3.310161      |\n",
      "| policy_loss        | -0.0019793874 |\n",
      "| serial_timesteps   | 51200         |\n",
      "| time_elapsed       | 1.73e+03      |\n",
      "| total_timesteps    | 204800        |\n",
      "| value_loss         | 0.0021133204  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0005442936  |\n",
      "| clipfrac           | 0.00048828125 |\n",
      "| ep_len_mean        | 1.51e+03      |\n",
      "| ep_reward_mean     | -2.08e+03     |\n",
      "| explained_variance | 0.992         |\n",
      "| fps                | 134           |\n",
      "| n_updates          | 450           |\n",
      "| policy_entropy     | 3.154624      |\n",
      "| policy_loss        | -0.0015804352 |\n",
      "| serial_timesteps   | 57600         |\n",
      "| time_elapsed       | 1.94e+03      |\n",
      "| total_timesteps    | 230400        |\n",
      "| value_loss         | 0.00093735254 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0018392806  |\n",
      "| clipfrac           | 0.021972656   |\n",
      "| ep_len_mean        | 1.55e+03      |\n",
      "| ep_reward_mean     | -1.92e+03     |\n",
      "| explained_variance | 0.907         |\n",
      "| fps                | 108           |\n",
      "| n_updates          | 500           |\n",
      "| policy_entropy     | 2.9651723     |\n",
      "| policy_loss        | -0.0067319735 |\n",
      "| serial_timesteps   | 64000         |\n",
      "| time_elapsed       | 2.14e+03      |\n",
      "| total_timesteps    | 256000        |\n",
      "| value_loss         | 0.001923557   |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0017575342 |\n",
      "| clipfrac           | 0.013671875  |\n",
      "| ep_len_mean        | 1.58e+03     |\n",
      "| ep_reward_mean     | -1.72e+03    |\n",
      "| explained_variance | 0.979        |\n",
      "| fps                | 131          |\n",
      "| n_updates          | 550          |\n",
      "| policy_entropy     | 2.8653228    |\n",
      "| policy_loss        | -0.008546882 |\n",
      "| serial_timesteps   | 70400        |\n",
      "| time_elapsed       | 2.34e+03     |\n",
      "| total_timesteps    | 281600       |\n",
      "| value_loss         | 0.0012415971 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0016643165 |\n",
      "| clipfrac           | 0.016113281  |\n",
      "| ep_len_mean        | 1.66e+03     |\n",
      "| ep_reward_mean     | -1.61e+03    |\n",
      "| explained_variance | 0.879        |\n",
      "| fps                | 125          |\n",
      "| n_updates          | 600          |\n",
      "| policy_entropy     | 2.7199082    |\n",
      "| policy_loss        | -0.010018354 |\n",
      "| serial_timesteps   | 76800        |\n",
      "| time_elapsed       | 2.54e+03     |\n",
      "| total_timesteps    | 307200       |\n",
      "| value_loss         | 0.17420502   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0017239485 |\n",
      "| clipfrac           | 0.0146484375 |\n",
      "| ep_len_mean        | 1.78e+03     |\n",
      "| ep_reward_mean     | -1.44e+03    |\n",
      "| explained_variance | 0.885        |\n",
      "| fps                | 133          |\n",
      "| n_updates          | 650          |\n",
      "| policy_entropy     | 2.640055     |\n",
      "| policy_loss        | -0.004719143 |\n",
      "| serial_timesteps   | 83200        |\n",
      "| time_elapsed       | 2.75e+03     |\n",
      "| total_timesteps    | 332800       |\n",
      "| value_loss         | 0.0061588986 |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0030796358  |\n",
      "| clipfrac           | 0.03173828    |\n",
      "| ep_len_mean        | 1.8e+03       |\n",
      "| ep_reward_mean     | -1.34e+03     |\n",
      "| explained_variance | 0.959         |\n",
      "| fps                | 129           |\n",
      "| n_updates          | 700           |\n",
      "| policy_entropy     | 2.5616996     |\n",
      "| policy_loss        | -0.010264094  |\n",
      "| serial_timesteps   | 89600         |\n",
      "| time_elapsed       | 2.95e+03      |\n",
      "| total_timesteps    | 358400        |\n",
      "| value_loss         | 0.00097288203 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0031471655  |\n",
      "| clipfrac           | 0.034179688   |\n",
      "| ep_len_mean        | 1.83e+03      |\n",
      "| ep_reward_mean     | -1.26e+03     |\n",
      "| explained_variance | 0.989         |\n",
      "| fps                | 123           |\n",
      "| n_updates          | 750           |\n",
      "| policy_entropy     | 2.37654       |\n",
      "| policy_loss        | -0.0016818047 |\n",
      "| serial_timesteps   | 96000         |\n",
      "| time_elapsed       | 3.16e+03      |\n",
      "| total_timesteps    | 384000        |\n",
      "| value_loss         | 0.00035555795 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0036902693  |\n",
      "| clipfrac           | 0.0390625     |\n",
      "| ep_len_mean        | 1.84e+03      |\n",
      "| ep_reward_mean     | -1.21e+03     |\n",
      "| explained_variance | 0.897         |\n",
      "| fps                | 123           |\n",
      "| n_updates          | 800           |\n",
      "| policy_entropy     | 2.2106106     |\n",
      "| policy_loss        | -0.009902942  |\n",
      "| serial_timesteps   | 102400        |\n",
      "| time_elapsed       | 3.37e+03      |\n",
      "| total_timesteps    | 409600        |\n",
      "| value_loss         | 0.00023830503 |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0043196497 |\n",
      "| clipfrac           | 0.055664062  |\n",
      "| ep_len_mean        | 1.85e+03     |\n",
      "| ep_reward_mean     | -1.16e+03    |\n",
      "| explained_variance | 0.835        |\n",
      "| fps                | 118          |\n",
      "| n_updates          | 850          |\n",
      "| policy_entropy     | 1.9983149    |\n",
      "| policy_loss        | -0.007251029 |\n",
      "| serial_timesteps   | 108800       |\n",
      "| time_elapsed       | 3.57e+03     |\n",
      "| total_timesteps    | 435200       |\n",
      "| value_loss         | 0.0034659095 |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0010202292  |\n",
      "| clipfrac           | 0.0053710938  |\n",
      "| ep_len_mean        | 1.88e+03      |\n",
      "| ep_reward_mean     | -1.09e+03     |\n",
      "| explained_variance | 0.969         |\n",
      "| fps                | 135           |\n",
      "| n_updates          | 900           |\n",
      "| policy_entropy     | 1.8837534     |\n",
      "| policy_loss        | -0.00240146   |\n",
      "| serial_timesteps   | 115200        |\n",
      "| time_elapsed       | 3.77e+03      |\n",
      "| total_timesteps    | 460800        |\n",
      "| value_loss         | 0.00012061531 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0039416896  |\n",
      "| clipfrac           | 0.03955078    |\n",
      "| ep_len_mean        | 1.91e+03      |\n",
      "| ep_reward_mean     | -1.03e+03     |\n",
      "| explained_variance | 0.994         |\n",
      "| fps                | 125           |\n",
      "| n_updates          | 950           |\n",
      "| policy_entropy     | 1.7672098     |\n",
      "| policy_loss        | -0.0070186984 |\n",
      "| serial_timesteps   | 121600        |\n",
      "| time_elapsed       | 3.97e+03      |\n",
      "| total_timesteps    | 486400        |\n",
      "| value_loss         | 0.0018125915  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.004942227   |\n",
      "| clipfrac           | 0.063964844   |\n",
      "| ep_len_mean        | 1.94e+03      |\n",
      "| ep_reward_mean     | -1.02e+03     |\n",
      "| explained_variance | 0.922         |\n",
      "| fps                | 132           |\n",
      "| n_updates          | 1000          |\n",
      "| policy_entropy     | 1.6250652     |\n",
      "| policy_loss        | -0.011805147  |\n",
      "| serial_timesteps   | 128000        |\n",
      "| time_elapsed       | 4.17e+03      |\n",
      "| total_timesteps    | 512000        |\n",
      "| value_loss         | 0.00039441392 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0011618143  |\n",
      "| clipfrac           | 0.0087890625  |\n",
      "| ep_len_mean        | 1.99e+03      |\n",
      "| ep_reward_mean     | -945          |\n",
      "| explained_variance | 0.794         |\n",
      "| fps                | 127           |\n",
      "| n_updates          | 1050          |\n",
      "| policy_entropy     | 1.4875984     |\n",
      "| policy_loss        | -0.0026779603 |\n",
      "| serial_timesteps   | 134400        |\n",
      "| time_elapsed       | 4.38e+03      |\n",
      "| total_timesteps    | 537600        |\n",
      "| value_loss         | 0.00021973328 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.004572877   |\n",
      "| clipfrac           | 0.05419922    |\n",
      "| ep_len_mean        | 1.99e+03      |\n",
      "| ep_reward_mean     | -869          |\n",
      "| explained_variance | 0.701         |\n",
      "| fps                | 125           |\n",
      "| n_updates          | 1100          |\n",
      "| policy_entropy     | 1.3825142     |\n",
      "| policy_loss        | -0.0047881086 |\n",
      "| serial_timesteps   | 140800        |\n",
      "| time_elapsed       | 4.58e+03      |\n",
      "| total_timesteps    | 563200        |\n",
      "| value_loss         | 0.0028000013  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0025052167  |\n",
      "| clipfrac           | 0.022949219   |\n",
      "| ep_len_mean        | 1.98e+03      |\n",
      "| ep_reward_mean     | -837          |\n",
      "| explained_variance | 0.99          |\n",
      "| fps                | 130           |\n",
      "| n_updates          | 1150          |\n",
      "| policy_entropy     | 1.2388858     |\n",
      "| policy_loss        | -0.0034850906 |\n",
      "| serial_timesteps   | 147200        |\n",
      "| time_elapsed       | 4.79e+03      |\n",
      "| total_timesteps    | 588800        |\n",
      "| value_loss         | 0.0016320423  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0062393025  |\n",
      "| clipfrac           | 0.08544922    |\n",
      "| ep_len_mean        | 1.98e+03      |\n",
      "| ep_reward_mean     | -800          |\n",
      "| explained_variance | 0.995         |\n",
      "| fps                | 128           |\n",
      "| n_updates          | 1200          |\n",
      "| policy_entropy     | 1.0694396     |\n",
      "| policy_loss        | -0.009240238  |\n",
      "| serial_timesteps   | 153600        |\n",
      "| time_elapsed       | 4.99e+03      |\n",
      "| total_timesteps    | 614400        |\n",
      "| value_loss         | 0.00017838879 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0022529475  |\n",
      "| clipfrac           | 0.0146484375  |\n",
      "| ep_len_mean        | 1.98e+03      |\n",
      "| ep_reward_mean     | -784          |\n",
      "| explained_variance | 0.98          |\n",
      "| fps                | 133           |\n",
      "| n_updates          | 1250          |\n",
      "| policy_entropy     | 0.9573236     |\n",
      "| policy_loss        | -0.0008487472 |\n",
      "| serial_timesteps   | 160000        |\n",
      "| time_elapsed       | 5.2e+03       |\n",
      "| total_timesteps    | 640000        |\n",
      "| value_loss         | 0.00015442337 |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 0.002303309    |\n",
      "| clipfrac           | 0.015136719    |\n",
      "| ep_len_mean        | 1.98e+03       |\n",
      "| ep_reward_mean     | -761           |\n",
      "| explained_variance | 0.994          |\n",
      "| fps                | 127            |\n",
      "| n_updates          | 1300           |\n",
      "| policy_entropy     | 0.82101667     |\n",
      "| policy_loss        | -0.0020540007  |\n",
      "| serial_timesteps   | 166400         |\n",
      "| time_elapsed       | 5.4e+03        |\n",
      "| total_timesteps    | 665600         |\n",
      "| value_loss         | 0.000103198276 |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.004466265   |\n",
      "| clipfrac           | 0.059570312   |\n",
      "| ep_len_mean        | 1.98e+03      |\n",
      "| ep_reward_mean     | -727          |\n",
      "| explained_variance | 0.997         |\n",
      "| fps                | 124           |\n",
      "| n_updates          | 1350          |\n",
      "| policy_entropy     | 0.7797672     |\n",
      "| policy_loss        | -0.0067454875 |\n",
      "| serial_timesteps   | 172800        |\n",
      "| time_elapsed       | 5.61e+03      |\n",
      "| total_timesteps    | 691200        |\n",
      "| value_loss         | 0.00014695777 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0035512396  |\n",
      "| clipfrac           | 0.04248047    |\n",
      "| ep_len_mean        | 1.98e+03      |\n",
      "| ep_reward_mean     | -711          |\n",
      "| explained_variance | 0.943         |\n",
      "| fps                | 128           |\n",
      "| n_updates          | 1400          |\n",
      "| policy_entropy     | 0.6755411     |\n",
      "| policy_loss        | -0.0051416545 |\n",
      "| serial_timesteps   | 179200        |\n",
      "| time_elapsed       | 5.82e+03      |\n",
      "| total_timesteps    | 716800        |\n",
      "| value_loss         | 0.0002802085  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.008021954   |\n",
      "| clipfrac           | 0.107421875   |\n",
      "| ep_len_mean        | 1.99e+03      |\n",
      "| ep_reward_mean     | -690          |\n",
      "| explained_variance | 0.769         |\n",
      "| fps                | 122           |\n",
      "| n_updates          | 1450          |\n",
      "| policy_entropy     | 0.58193696    |\n",
      "| policy_loss        | -0.008552065  |\n",
      "| serial_timesteps   | 185600        |\n",
      "| time_elapsed       | 6.03e+03      |\n",
      "| total_timesteps    | 742400        |\n",
      "| value_loss         | 0.00032761847 |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.006737824  |\n",
      "| clipfrac           | 0.07714844   |\n",
      "| ep_len_mean        | 1.99e+03     |\n",
      "| ep_reward_mean     | -673         |\n",
      "| explained_variance | 0.966        |\n",
      "| fps                | 122          |\n",
      "| n_updates          | 1500         |\n",
      "| policy_entropy     | 0.4958611    |\n",
      "| policy_loss        | -0.009421311 |\n",
      "| serial_timesteps   | 192000       |\n",
      "| time_elapsed       | 6.24e+03     |\n",
      "| total_timesteps    | 768000       |\n",
      "| value_loss         | 0.0006610362 |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0038411077  |\n",
      "| clipfrac           | 0.044433594   |\n",
      "| ep_len_mean        | 2e+03         |\n",
      "| ep_reward_mean     | -632          |\n",
      "| explained_variance | 0.947         |\n",
      "| fps                | 127           |\n",
      "| n_updates          | 1550          |\n",
      "| policy_entropy     | 0.3949788     |\n",
      "| policy_loss        | -0.0043821028 |\n",
      "| serial_timesteps   | 198400        |\n",
      "| time_elapsed       | 6.46e+03      |\n",
      "| total_timesteps    | 793600        |\n",
      "| value_loss         | 0.0001246976  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.004868809   |\n",
      "| clipfrac           | 0.063964844   |\n",
      "| ep_len_mean        | 2e+03         |\n",
      "| ep_reward_mean     | -616          |\n",
      "| explained_variance | 0.973         |\n",
      "| fps                | 119           |\n",
      "| n_updates          | 1600          |\n",
      "| policy_entropy     | 0.25396985    |\n",
      "| policy_loss        | -0.0052015376 |\n",
      "| serial_timesteps   | 204800        |\n",
      "| time_elapsed       | 6.67e+03      |\n",
      "| total_timesteps    | 819200        |\n",
      "| value_loss         | 0.0001006715  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0043168524  |\n",
      "| clipfrac           | 0.051757812   |\n",
      "| ep_len_mean        | 2e+03         |\n",
      "| ep_reward_mean     | -601          |\n",
      "| explained_variance | 0.995         |\n",
      "| fps                | 124           |\n",
      "| n_updates          | 1650          |\n",
      "| policy_entropy     | 0.12031016    |\n",
      "| policy_loss        | -0.0074479296 |\n",
      "| serial_timesteps   | 211200        |\n",
      "| time_elapsed       | 6.88e+03      |\n",
      "| total_timesteps    | 844800        |\n",
      "| value_loss         | 9.312727e-05  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.008596839   |\n",
      "| clipfrac           | 0.119140625   |\n",
      "| ep_len_mean        | 2e+03         |\n",
      "| ep_reward_mean     | -586          |\n",
      "| explained_variance | 0.985         |\n",
      "| fps                | 120           |\n",
      "| n_updates          | 1700          |\n",
      "| policy_entropy     | 0.037752345   |\n",
      "| policy_loss        | -0.008647031  |\n",
      "| serial_timesteps   | 217600        |\n",
      "| time_elapsed       | 7.1e+03       |\n",
      "| total_timesteps    | 870400        |\n",
      "| value_loss         | 0.00025477223 |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0054761847 |\n",
      "| clipfrac           | 0.07324219   |\n",
      "| ep_len_mean        | 2e+03        |\n",
      "| ep_reward_mean     | -565         |\n",
      "| explained_variance | 0.966        |\n",
      "| fps                | 128          |\n",
      "| n_updates          | 1750         |\n",
      "| policy_entropy     | -0.1535052   |\n",
      "| policy_loss        | -0.004063963 |\n",
      "| serial_timesteps   | 224000       |\n",
      "| time_elapsed       | 7.31e+03     |\n",
      "| total_timesteps    | 896000       |\n",
      "| value_loss         | 2.818718e-05 |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.007780381  |\n",
      "| clipfrac           | 0.09667969   |\n",
      "| ep_len_mean        | 2e+03        |\n",
      "| ep_reward_mean     | -521         |\n",
      "| explained_variance | 0.934        |\n",
      "| fps                | 115          |\n",
      "| n_updates          | 1800         |\n",
      "| policy_entropy     | -0.37938094  |\n",
      "| policy_loss        | -0.006819224 |\n",
      "| serial_timesteps   | 230400       |\n",
      "| time_elapsed       | 7.52e+03     |\n",
      "| total_timesteps    | 921600       |\n",
      "| value_loss         | 3.972347e-05 |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 0.0029008477   |\n",
      "| clipfrac           | 0.032226562    |\n",
      "| ep_len_mean        | 2e+03          |\n",
      "| ep_reward_mean     | -490           |\n",
      "| explained_variance | 0.998          |\n",
      "| fps                | 121            |\n",
      "| n_updates          | 1850           |\n",
      "| policy_entropy     | -0.5803406     |\n",
      "| policy_loss        | -0.0013206297  |\n",
      "| serial_timesteps   | 236800         |\n",
      "| time_elapsed       | 7.74e+03       |\n",
      "| total_timesteps    | 947200         |\n",
      "| value_loss         | 1.12748485e-05 |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.007417968   |\n",
      "| clipfrac           | 0.10644531    |\n",
      "| ep_len_mean        | 2e+03         |\n",
      "| ep_reward_mean     | -451          |\n",
      "| explained_variance | 0.963         |\n",
      "| fps                | 124           |\n",
      "| n_updates          | 1900          |\n",
      "| policy_entropy     | -0.74149257   |\n",
      "| policy_loss        | -0.0051662982 |\n",
      "| serial_timesteps   | 243200        |\n",
      "| time_elapsed       | 7.95e+03      |\n",
      "| total_timesteps    | 972800        |\n",
      "| value_loss         | 0.0005953405  |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0061934963 |\n",
      "| clipfrac           | 0.07861328   |\n",
      "| ep_len_mean        | 2e+03        |\n",
      "| ep_reward_mean     | -405         |\n",
      "| explained_variance | 0.996        |\n",
      "| fps                | 118          |\n",
      "| n_updates          | 1950         |\n",
      "| policy_entropy     | -0.9437764   |\n",
      "| policy_loss        | -0.005718175 |\n",
      "| serial_timesteps   | 249600       |\n",
      "| time_elapsed       | 8.17e+03     |\n",
      "| total_timesteps    | 998400       |\n",
      "| value_loss         | 2.145516e-05 |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "IsADirectoryError",
     "evalue": "[Errno 21] Is a directory: 'test_sets/'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-d4e6d18ae28b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexamples_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrain_rl_controller\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"reproduceMLP\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_envs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisable_curriculum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"MLP\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000000\u001b[0m\u001b[0;34m,\u001b[0m                     \u001b[0mtest_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"test_sets/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/Github/Uni/Master/tum-adlr-ws20-08/magpie/libs/fixed-wing-gym/gym_fixed_wing/examples/train_rl_controller.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(model_name, num_envs, env_config_path, train_steps, policy, disable_curriculum, test_path)\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mlog_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog_interval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m         \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmonitor_training\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m     )\n\u001b[1;32m    329\u001b[0m     \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/adlr/lib/python3.6/site-packages/stable_baselines/ppo2/ppo2.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, seed, log_interval, tb_log_name, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    397\u001b[0m                     \u001b[0;31m# Only stop training if return value is False, not when it is None. This is for backwards\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m                     \u001b[0;31m# compatibility with callbacks that have no return statement.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m                         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Github/Uni/Master/tum-adlr-ws20-08/magpie/libs/fixed-wing-gym/gym_fixed_wing/examples/train_rl_controller.py\u001b[0m in \u001b[0;36mmonitor_training\u001b[0;34m(_locals, _globals)\u001b[0m\n\u001b[1;32m    161\u001b[0m                 \u001b[0mnum_envs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_locals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"self\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \u001b[0mwriter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_locals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"writer\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m                 \u001b[0mtimestep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_locals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"self\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m             )\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Github/Uni/Master/tum-adlr-ws20-08/magpie/libs/fixed-wing-gym/gym_fixed_wing/examples/evaluate_controller.py\u001b[0m in \u001b[0;36mevaluate_model_on_set\u001b[0;34m(set_path, model, config_path, config_kw, metrics, norm_data_path, num_envs, turbulence_intensity, use_pid, writer, timestep)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0mcomputed\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mevaluated\u001b[0m \u001b[0mcontroller\u001b[0m \u001b[0mon\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtest\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \"\"\"\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0mscenarios\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m     \u001b[0mscenario_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscenarios\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/adlr/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    414\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIsADirectoryError\u001b[0m: [Errno 21] Is a directory: 'test_sets/'"
     ]
    }
   ],
   "source": [
    "os.chdir(examples_dir)\n",
    "if __name__ == '__main__':\n",
    "    train_rl_controller.main(model_name=\"reproduceMLP\", num_envs=4, disable_curriculum=True, policy=\"MLP\", train_steps=5000000,                     test_data_path=\"test_sets/test_set_wind_none_step20-20-3.npy\")"
   ]
  },
  {
   "source": [
    "## Evaluation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym_fixed_wing.examples import evaluate_controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "100/100 scenarios left\n",
      "99/100 scenarios left\n",
      "98/100 scenarios left\n",
      "97/100 scenarios left\n",
      "96/100 scenarios left\n",
      "95/100 scenarios left\n",
      "94/100 scenarios left\n",
      "93/100 scenarios left\n",
      "92/100 scenarios left\n",
      "91/100 scenarios left\n",
      "90/100 scenarios left\n",
      "89/100 scenarios left\n",
      "88/100 scenarios left\n",
      "87/100 scenarios left\n",
      "86/100 scenarios left\n",
      "85/100 scenarios left\n",
      "84/100 scenarios left\n",
      "83/100 scenarios left\n",
      "82/100 scenarios left\n",
      "81/100 scenarios left\n",
      "80/100 scenarios left\n",
      "79/100 scenarios left\n",
      "78/100 scenarios left\n",
      "77/100 scenarios left\n",
      "76/100 scenarios left\n",
      "75/100 scenarios left\n",
      "74/100 scenarios left\n",
      "73/100 scenarios left\n",
      "72/100 scenarios left\n",
      "71/100 scenarios left\n",
      "70/100 scenarios left\n",
      "69/100 scenarios left\n",
      "68/100 scenarios left\n",
      "67/100 scenarios left\n",
      "66/100 scenarios left\n",
      "65/100 scenarios left\n",
      "64/100 scenarios left\n",
      "63/100 scenarios left\n",
      "62/100 scenarios left\n",
      "61/100 scenarios left\n",
      "60/100 scenarios left\n",
      "59/100 scenarios left\n",
      "58/100 scenarios left\n",
      "57/100 scenarios left\n",
      "56/100 scenarios left\n",
      "55/100 scenarios left\n",
      "54/100 scenarios left\n",
      "53/100 scenarios left\n",
      "52/100 scenarios left\n",
      "51/100 scenarios left\n",
      "50/100 scenarios left\n",
      "49/100 scenarios left\n",
      "48/100 scenarios left\n",
      "47/100 scenarios left\n",
      "46/100 scenarios left\n",
      "45/100 scenarios left\n",
      "44/100 scenarios left\n",
      "43/100 scenarios left\n",
      "42/100 scenarios left\n",
      "41/100 scenarios left\n",
      "40/100 scenarios left\n",
      "39/100 scenarios left\n",
      "38/100 scenarios left\n",
      "37/100 scenarios left\n",
      "36/100 scenarios left\n",
      "35/100 scenarios left\n",
      "34/100 scenarios left\n",
      "33/100 scenarios left\n",
      "32/100 scenarios left\n",
      "31/100 scenarios left\n",
      "30/100 scenarios left\n",
      "29/100 scenarios left\n",
      "28/100 scenarios left\n",
      "27/100 scenarios left\n",
      "26/100 scenarios left\n",
      "25/100 scenarios left\n",
      "24/100 scenarios left\n",
      "23/100 scenarios left\n",
      "22/100 scenarios left\n",
      "21/100 scenarios left\n",
      "20/100 scenarios left\n",
      "19/100 scenarios left\n",
      "18/100 scenarios left\n",
      "17/100 scenarios left\n",
      "16/100 scenarios left\n",
      "15/100 scenarios left\n",
      "14/100 scenarios left\n",
      "13/100 scenarios left\n",
      "12/100 scenarios left\n",
      "11/100 scenarios left\n",
      "10/100 scenarios left\n",
      "9/100 scenarios left\n",
      "8/100 scenarios left\n",
      "7/100 scenarios left\n",
      "6/100 scenarios left\n",
      "5/100 scenarios left\n",
      "4/100 scenarios left\n",
      "3/100 scenarios left\n",
      "2/100 scenarios left\n",
      "1/100 scenarios left\n",
      "success\n",
      "\troll:\t1.0\n",
      "\tpitch:\t1.0\n",
      "\tVa:\t1.0\n",
      "\tall:\t1.0\n",
      "control_variation\n",
      "\tall:\t0.28239413772665256\n",
      "rise_time\n",
      "\troll:\t133.65591397849462\n",
      "\tpitch:\t22.6\n",
      "\tVa:\t101.53571428571429\n",
      "overshoot\n",
      "\troll:\t0.03491744001110296\n",
      "\tpitch:\t0.09607746595448735\n",
      "\tVa:\t0.2892483662133038\n",
      "settling_time\n",
      "\troll:\t201.72\n",
      "\tpitch:\t129.36\n",
      "\tVa:\t220.15\n",
      "\tall:\t253.46\n"
     ]
    }
   ],
   "source": [
    "os.chdir(examples_dir)\n",
    "# needed to avoid that multiprocessing creates recursive subprocesses\n",
    "if __name__ == '__main__':\n",
    "    evaluate_controller.main(path_to_file=\"test_sets/test_set_wind_none_step20-20-3.npy\", num_envs=4,\n",
    "    use_pid=True, env_config_path=\"fixed_wing_config.json\", turbulence_intensity=\"None\", print_res=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading a model without an environment, this model cannot be trained until it has a valid environment.\n",
      "WARNING:tensorflow:From /home/user/Documents/Github/Uni/Master/tum-adlr-ws20-08/papers/stable-baselines/stable_baselines/common/policies.py:954: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From /home/user/miniconda3/envs/adlr/lib/python3.7/site-packages/tensorflow_core/python/layers/core.py:332: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From /home/user/Documents/Github/Uni/Master/tum-adlr-ws20-08/papers/stable-baselines/stable_baselines/common/tf_layers.py:123: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/user/Documents/Github/Uni/Master/tum-adlr-ws20-08/papers/stable-baselines/stable_baselines/common/distributions.py:452: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/user/Documents/Github/Uni/Master/tum-adlr-ws20-08/papers/stable-baselines/stable_baselines/common/distributions.py:154: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/user/Documents/Github/Uni/Master/tum-adlr-ws20-08/papers/stable-baselines/stable_baselines/ppo2/ppo2.py:194: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/user/Documents/Github/Uni/Master/tum-adlr-ws20-08/papers/stable-baselines/stable_baselines/ppo2/ppo2.py:202: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/user/miniconda3/envs/adlr/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/user/Documents/Github/Uni/Master/tum-adlr-ws20-08/papers/stable-baselines/stable_baselines/ppo2/ppo2.py:210: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/user/Documents/Github/Uni/Master/tum-adlr-ws20-08/papers/stable-baselines/stable_baselines/ppo2/ppo2.py:244: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/user/Documents/Github/Uni/Master/tum-adlr-ws20-08/papers/stable-baselines/stable_baselines/ppo2/ppo2.py:246: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "100/100 scenarios left\n",
      "99/100 scenarios left\n",
      "98/100 scenarios left\n",
      "97/100 scenarios left\n",
      "96/100 scenarios left\n",
      "95/100 scenarios left\n",
      "94/100 scenarios left\n",
      "93/100 scenarios left\n",
      "92/100 scenarios left\n",
      "91/100 scenarios left\n",
      "90/100 scenarios left\n",
      "89/100 scenarios left\n",
      "88/100 scenarios left\n",
      "87/100 scenarios left\n",
      "86/100 scenarios left\n",
      "85/100 scenarios left\n",
      "84/100 scenarios left\n",
      "83/100 scenarios left\n",
      "82/100 scenarios left\n",
      "81/100 scenarios left\n",
      "80/100 scenarios left\n",
      "79/100 scenarios left\n",
      "78/100 scenarios left\n",
      "77/100 scenarios left\n",
      "76/100 scenarios left\n",
      "75/100 scenarios left\n",
      "74/100 scenarios left\n",
      "73/100 scenarios left\n",
      "72/100 scenarios left\n",
      "71/100 scenarios left\n",
      "70/100 scenarios left\n",
      "69/100 scenarios left\n",
      "68/100 scenarios left\n",
      "67/100 scenarios left\n",
      "66/100 scenarios left\n",
      "65/100 scenarios left\n",
      "64/100 scenarios left\n",
      "63/100 scenarios left\n",
      "62/100 scenarios left\n",
      "61/100 scenarios left\n",
      "60/100 scenarios left\n",
      "59/100 scenarios left\n",
      "58/100 scenarios left\n",
      "57/100 scenarios left\n",
      "56/100 scenarios left\n",
      "55/100 scenarios left\n",
      "54/100 scenarios left\n",
      "53/100 scenarios left\n",
      "52/100 scenarios left\n",
      "51/100 scenarios left\n",
      "50/100 scenarios left\n",
      "49/100 scenarios left\n",
      "48/100 scenarios left\n",
      "47/100 scenarios left\n",
      "46/100 scenarios left\n",
      "45/100 scenarios left\n",
      "44/100 scenarios left\n",
      "43/100 scenarios left\n",
      "42/100 scenarios left\n",
      "41/100 scenarios left\n",
      "40/100 scenarios left\n",
      "39/100 scenarios left\n",
      "38/100 scenarios left\n",
      "37/100 scenarios left\n",
      "36/100 scenarios left\n",
      "35/100 scenarios left\n",
      "34/100 scenarios left\n",
      "33/100 scenarios left\n",
      "32/100 scenarios left\n",
      "31/100 scenarios left\n",
      "30/100 scenarios left\n",
      "29/100 scenarios left\n",
      "28/100 scenarios left\n",
      "27/100 scenarios left\n",
      "26/100 scenarios left\n",
      "25/100 scenarios left\n",
      "24/100 scenarios left\n",
      "23/100 scenarios left\n",
      "22/100 scenarios left\n",
      "21/100 scenarios left\n",
      "20/100 scenarios left\n",
      "19/100 scenarios left\n",
      "18/100 scenarios left\n",
      "17/100 scenarios left\n",
      "16/100 scenarios left\n",
      "15/100 scenarios left\n",
      "14/100 scenarios left\n",
      "13/100 scenarios left\n",
      "12/100 scenarios left\n",
      "11/100 scenarios left\n",
      "10/100 scenarios left\n",
      "9/100 scenarios left\n",
      "8/100 scenarios left\n",
      "7/100 scenarios left\n",
      "6/100 scenarios left\n",
      "5/100 scenarios left\n",
      "4/100 scenarios left\n",
      "3/100 scenarios left\n",
      "2/100 scenarios left\n",
      "1/100 scenarios left\n",
      "success\n",
      "\troll:\t0.98\n",
      "\tpitch:\t0.97\n",
      "\tVa:\t0.97\n",
      "\tall:\t0.97\n",
      "control_variation\n",
      "\tall:\t1.2784630598842677\n",
      "rise_time\n",
      "\troll:\t89.02150537634408\n",
      "\tpitch:\t67.97872340425532\n",
      "\tVa:\t64.30909090909091\n",
      "overshoot\n",
      "\troll:\t0.45834825782375777\n",
      "\tpitch:\t0.5213400202716104\n",
      "\tVa:\t0.9096450456948966\n",
      "settling_time\n",
      "\troll:\t279.88659793814435\n",
      "\tpitch:\t292.6701030927835\n",
      "\tVa:\t366.03092783505156\n",
      "\tall:\t385.7319587628866\n"
     ]
    }
   ],
   "source": [
    "os.chdir(examples_dir)\n",
    "# needed to avoid that multiprocessing creates recursive subprocesses\n",
    "if __name__ == '__main__':\n",
    "    evaluate_controller.main(path_to_file=\"test_sets/test_set_wind_moderate_step20-20-3.npy\", num_envs=4, model_path=\"models/mlp_controller/model.pkl\", turbulence_intensity=\"moderate\", print_res=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading a model without an environment, this model cannot be trained until it has a valid environment.\n",
      "WARNING:tensorflow:From /home/user/miniconda3/envs/adlr/lib/python3.6/site-packages/stable_baselines/common/tf_util.py:191: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/user/miniconda3/envs/adlr/lib/python3.6/site-packages/stable_baselines/common/tf_util.py:200: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/user/miniconda3/envs/adlr/lib/python3.6/site-packages/stable_baselines/common/policies.py:116: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/user/miniconda3/envs/adlr/lib/python3.6/site-packages/stable_baselines/common/input.py:25: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/user/miniconda3/envs/adlr/lib/python3.6/site-packages/stable_baselines/common/policies.py:561: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From /home/user/miniconda3/envs/adlr/lib/python3.6/site-packages/tensorflow_core/python/layers/core.py:332: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From /home/user/miniconda3/envs/adlr/lib/python3.6/site-packages/stable_baselines/common/tf_layers.py:123: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/user/miniconda3/envs/adlr/lib/python3.6/site-packages/stable_baselines/common/distributions.py:418: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/user/miniconda3/envs/adlr/lib/python3.6/site-packages/stable_baselines/ppo2/ppo2.py:190: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/user/miniconda3/envs/adlr/lib/python3.6/site-packages/stable_baselines/ppo2/ppo2.py:198: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/user/miniconda3/envs/adlr/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/user/miniconda3/envs/adlr/lib/python3.6/site-packages/stable_baselines/ppo2/ppo2.py:206: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/user/miniconda3/envs/adlr/lib/python3.6/site-packages/stable_baselines/ppo2/ppo2.py:240: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/user/miniconda3/envs/adlr/lib/python3.6/site-packages/stable_baselines/ppo2/ppo2.py:242: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/user/miniconda3/envs/adlr/lib/python3.6/site-packages/stable_baselines/common/misc_util.py:26: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n",
      "100/100 scenarios left\n",
      "99/100 scenarios left\n",
      "98/100 scenarios left\n",
      "97/100 scenarios left\n",
      "96/100 scenarios left\n",
      "95/100 scenarios left\n",
      "94/100 scenarios left\n",
      "93/100 scenarios left\n",
      "92/100 scenarios left\n",
      "91/100 scenarios left\n",
      "90/100 scenarios left\n",
      "89/100 scenarios left\n",
      "88/100 scenarios left\n",
      "87/100 scenarios left\n",
      "86/100 scenarios left\n",
      "85/100 scenarios left\n",
      "84/100 scenarios left\n",
      "83/100 scenarios left\n",
      "82/100 scenarios left\n",
      "81/100 scenarios left\n",
      "80/100 scenarios left\n",
      "79/100 scenarios left\n",
      "78/100 scenarios left\n",
      "77/100 scenarios left\n",
      "76/100 scenarios left\n",
      "75/100 scenarios left\n",
      "74/100 scenarios left\n",
      "73/100 scenarios left\n",
      "72/100 scenarios left\n",
      "71/100 scenarios left\n",
      "70/100 scenarios left\n",
      "69/100 scenarios left\n",
      "68/100 scenarios left\n",
      "67/100 scenarios left\n",
      "66/100 scenarios left\n",
      "65/100 scenarios left\n",
      "64/100 scenarios left\n",
      "63/100 scenarios left\n",
      "62/100 scenarios left\n",
      "61/100 scenarios left\n",
      "60/100 scenarios left\n",
      "59/100 scenarios left\n",
      "58/100 scenarios left\n",
      "57/100 scenarios left\n",
      "56/100 scenarios left\n",
      "55/100 scenarios left\n",
      "54/100 scenarios left\n",
      "53/100 scenarios left\n",
      "52/100 scenarios left\n",
      "51/100 scenarios left\n",
      "50/100 scenarios left\n",
      "49/100 scenarios left\n",
      "48/100 scenarios left\n",
      "47/100 scenarios left\n",
      "46/100 scenarios left\n",
      "45/100 scenarios left\n",
      "44/100 scenarios left\n",
      "43/100 scenarios left\n",
      "42/100 scenarios left\n",
      "41/100 scenarios left\n",
      "40/100 scenarios left\n",
      "39/100 scenarios left\n",
      "38/100 scenarios left\n",
      "37/100 scenarios left\n",
      "36/100 scenarios left\n",
      "35/100 scenarios left\n",
      "34/100 scenarios left\n",
      "33/100 scenarios left\n",
      "32/100 scenarios left\n",
      "31/100 scenarios left\n",
      "30/100 scenarios left\n",
      "29/100 scenarios left\n",
      "28/100 scenarios left\n",
      "27/100 scenarios left\n",
      "26/100 scenarios left\n",
      "25/100 scenarios left\n",
      "24/100 scenarios left\n",
      "23/100 scenarios left\n",
      "22/100 scenarios left\n",
      "21/100 scenarios left\n",
      "20/100 scenarios left\n",
      "19/100 scenarios left\n",
      "18/100 scenarios left\n",
      "17/100 scenarios left\n",
      "16/100 scenarios left\n",
      "15/100 scenarios left\n",
      "14/100 scenarios left\n",
      "13/100 scenarios left\n",
      "12/100 scenarios left\n",
      "11/100 scenarios left\n",
      "10/100 scenarios left\n",
      "9/100 scenarios left\n",
      "8/100 scenarios left\n",
      "7/100 scenarios left\n",
      "6/100 scenarios left\n",
      "5/100 scenarios left\n",
      "4/100 scenarios left\n",
      "3/100 scenarios left\n",
      "2/100 scenarios left\n",
      "1/100 scenarios left\n",
      "success\n",
      "\troll:\t0.74\n",
      "\tpitch:\t0.75\n",
      "\tVa:\t0.53\n",
      "\tall:\t0.4\n",
      "control_variation\n",
      "\tall:\t0.3984460512668006\n",
      "rise_time\n",
      "\troll:\t197.13333333333333\n",
      "\tpitch:\t103.87179487179488\n",
      "\tVa:\t124.08571428571429\n",
      "overshoot\n",
      "\troll:\t0.6463093643040478\n",
      "\tpitch:\t0.6742408833954939\n",
      "\tVa:\t1.6437931978269755\n",
      "settling_time\n",
      "\troll:\t508.05\n",
      "\tpitch:\t426.025\n",
      "\tVa:\t445.025\n",
      "\tall:\t611.1\n"
     ]
    }
   ],
   "source": [
    "os.chdir(examples_dir)\n",
    "# needed to avoid that multiprocessing creates recursive subprocesses\n",
    "if __name__ == '__main__':\n",
    "    evaluate_controller.main(path_to_file=\"test_sets/test_set_wind_moderate_step20-20-3.npy\", num_envs=4, model_path=\"models/reproduceMLP/model.pkl\", turbulence_intensity=\"moderate\", print_res=False)"
   ]
  },
  {
   "source": [
    "```shell\n",
    "    tensorboard --logdir models/reproduceMLP/tb\n",
    "```\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "![tensorboard log](../../libs/fixed-wing-gym/gym_fixed_wing/examples/models/reproduceMLP/tensorboard_log.png)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "success\n\troll:\t0.98\n\tpitch:\t0.98\n\tVa:\t0.97\n\tall:\t0.97\ncontrol_variation\n\tall:\t0.8850109746249458\nrise_time\n\troll:\t14.840425531914894\n\tpitch:\t149.23595505617976\n\tVa:\t34.86538461538461\novershoot\n\troll:\t0.9015139050870169\n\tpitch:\t1.5196833654123265\n\tVa:\t2.254732935986987\nsettling_time\n\troll:\t223.1958762886598\n\tpitch:\t245.84536082474227\n\tVa:\t614.5876288659794\n\tall:\t624.319587628866\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "SystemExit",
     "evalue": "0",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 0\n"
     ]
    }
   ],
   "source": [
    "os.chdir(examples_dir)\n",
    "# needed to avoid that multiprocessing creates recursive subprocesses\n",
    "if __name__ == '__main__':\n",
    "    evaluate_controller.main(path_to_file=\"evaluations/eval_res_RL_CNN_severe.npy\", print_res=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load latest evaluation result\n",
    "import numpy as np\n",
    "os.chdir(examples_dir)\n",
    "res = np.load(\"eval_res.npy\", allow_pickle=True).item()\n",
    "res"
   ]
  },
  {
   "source": [
    "# Information from Readme"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Evaluating controllers\n",
    "The test_sets folder contains the four test sets used in the paper. Controllers can be evaluated on these sets by doing e.g.:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "first cd into the directory: papers/fixed-wing-gym/gym_fixed_wing/examples/"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "```shell\n",
    "python evaluate_controller.py test_sets/test_set_wind_none_step20-20-3.npy --num-envs 4 --PID --env-config-path fixed_wing_config.json --turbulence-intensity \"none\"\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Or:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "```shell\n",
    "python evaluate_controller.py test_sets/test_set_wind_moderate_step20-20-3.npy --num-envs 4 --model-path models/mlp_controller/model.pkl --turbulence-intensity \"moderate\"\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Which will evaluate the PID controller on the test set with no wind or turbulence and the MLP controller on the moderate turbulence set, respectively. The model folder contains the CNN RL controller used in the paper, as well as an MLP RL controller usable with the default version of stable-baselines.\n",
    "The outputs of the evaluation scripts can be found in the evaluations folder. They are in numpy format and contain the result dictionary, to process them in python do:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = np.load(\"eval_res.npy\", allow_pickle=True).item()"
   ]
  },
  {
   "source": [
    "Evaluation results can also be outputted by supplying the evaluation results file path in place of the test set path along with the --print-results flag:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "```shell\n",
    "python evaluate_controller.py evaluations/eval_res_RL_CNN_severe.npy --print-results\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Training controllers\n",
    "\n",
    "To train a reinforcement learning controller, run the train_rl_controller.py script, e.g. to train an agent using 4 processes for 5 million time steps and evaluate on the no turbulence test set, do:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "```shell\n",
    "python train_rl_controller.py \"ppo_example\" 4 --test-set-path test_sets/test_set_wind_none_step20-20-3.npy\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "This script trains a PPO agent to do attitude control of a fixed-wing aircraft. It saves checkpoints of models, renders episodes\n",
    " during training so that its behavior can be inspected, runs periodic test set evaluations if a test set path is supplied, and logs\n",
    " all training information to tensorboard such that its progress can be monitored."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "```shell\n",
    "tensorboard --logdir models/ppo_example/tb\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "![tensorboard log](../../libs/fixed-wing-gym/gym_fixed_wing/examples/tensorboard.png)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}